import time
import json
import requests
from Bio.PDB import PDBParser, PPBuilder
import re
from typing import List, Dict, Any
from goatools.obo_parser import GODag
from goatools.goea.go_enrichment_ns import GOEnrichmentStudyNS
from collections import Counter
from typing import List, Dict, Any

# =====================================================
# å‡½æ•°1ï¸âƒ£ï¼šä»PDBæ–‡ä»¶ä¸­æå–è›‹ç™½è´¨åºåˆ—
# =====================================================
def extract_sequence_from_pdb(pdb_file, chain_id=None):
    """
    ä» PDB æ–‡ä»¶ä¸­æå–è›‹ç™½è´¨æ°¨åŸºé…¸åºåˆ—
    å‚æ•°:
        pdb_file (str): PDBæ–‡ä»¶è·¯å¾„
        chain_id (str, å¯é€‰): æŒ‡å®šé“¾IDï¼ˆé»˜è®¤æå–ç¬¬ä¸€ä¸ªæ¨¡å‹çš„æ‰€æœ‰é“¾ï¼‰
    è¿”å›:
        str: è›‹ç™½è´¨åºåˆ—
    """
    parser = PDBParser(QUIET=True)
    structure = parser.get_structure("protein", pdb_file)
    ppb = PPBuilder()

    sequence = ""
    for model in structure:
        for chain in model:
            if chain_id and chain.id != chain_id:
                continue
            for pp in ppb.build_peptides(chain):
                sequence += str(pp.get_sequence())
        break  # åªå–ç¬¬ä¸€ä¸ª model
    return sequence

# =====================================================
# å‡½æ•°2ï¸âƒ£ï¼šåŸºäº InterProScan API çš„åºåˆ—åŠŸèƒ½é¢„æµ‹
# =====================================================
def interpro_predict(sequence, email="your_email@example.com", wait_interval=20):
    """
    ä½¿ç”¨ EBI InterProScan API å¯¹è›‹ç™½è´¨åºåˆ—è¿›è¡ŒåŠŸèƒ½é¢„æµ‹

    å‚æ•°:
        sequence (str): è›‹ç™½è´¨æ°¨åŸºé…¸åºåˆ—
        email (str): ä½ çš„é‚®ç®±ï¼ˆEBIè¦æ±‚ç”¨äºä»»åŠ¡æ ‡è¯†ï¼‰
        wait_interval (int): æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€çš„é—´éš”ç§’æ•°

    è¿”å›:
        dict: InterProScan çš„é¢„æµ‹ç»“æœ(JSONå¯¹è±¡)
    """
    # Step 1: æäº¤ä»»åŠ¡
    run_url = "https://www.ebi.ac.uk/Tools/services/rest/iprscan5/run/"
    payload = {
        "email": email,
        "title": "InterProScan_from_PDB",
        "sequence": sequence
    }

    print("[ğŸš€] æäº¤åºåˆ—åˆ° InterProScan ...")
    response = requests.post(run_url, data=payload)
    if response.status_code != 200:
        raise Exception(f"æäº¤å¤±è´¥: {response.text}")
    job_id = response.text.strip()
    print(f"[âœ…] ä»»åŠ¡å·²æäº¤ï¼ŒJob ID: {job_id}")

    # Step 2: ç­‰å¾…ä»»åŠ¡å®Œæˆ
    status_url = f"https://www.ebi.ac.uk/Tools/services/rest/iprscan5/status/{job_id}"
    while True:
        status = requests.get(status_url).text.strip()
        print(f"[âŒ›] å½“å‰çŠ¶æ€: {status}")
        if status == "FINISHED":
            print("[âœ…] ä»»åŠ¡å®Œæˆï¼")
            break
        elif status in ["ERROR", "FAILURE"]:
            raise Exception("InterProScan ä»»åŠ¡å¤±è´¥ï¼")
        time.sleep(wait_interval)

    # Step 3: è·å–ç»“æœï¼ˆJSON æ ¼å¼ï¼‰
    result_url = f"https://www.ebi.ac.uk/Tools/services/rest/iprscan5/result/{job_id}/json"
    result_response = requests.get(result_url)
    if result_response.status_code != 200:
        raise Exception(f"ç»“æœè·å–å¤±è´¥: {result_response.text}")

    result = result_response.json()
    print("[ğŸ’¾] è·å–é¢„æµ‹ç»“æœæˆåŠŸï¼")
    return result

# =====================================================
# å‡½æ•°3ï¸âƒ£ï¼šæ•´ç†æ•°æ®
# =====================================================
def extract_main_data(result: Dict[str, Any]) -> List[Dict[str, Any]]:
    """
    ä» interproscan-style çš„ result ä¸­æå–æ•°æ®ï¼ŒåªåŒ…å« locations ä¸­ representative=True çš„è®°å½•ã€‚
    æ¯æ¡è®°å½•åŒ…å«ï¼š
      - accession (from signature)
      - name (from signature)
      - signature_description (from signature.description)
      - entry_accession (from signature.entry.accession)
      - entry_description (from signature.entry.description)
      - go_terms: list of dicts, each {'id','name','category'} (å¯ä¸ºç©ºåˆ—è¡¨)
      - start, end, score (from location)
      - model_ac (from match['model-ac'])
      - alignment (from location)
    """
    out = []

    results = result.get('results') or []
    if isinstance(results, dict):
        results = [results]

    for res_item in results:
        matches = res_item.get('matches', []) or []
        for match in matches:
            signature = match.get('signature', {}) or {}
            entry = signature.get('entry', {}) or {}

            # locations é€šå¸¸æ˜¯åˆ—è¡¨
            locations = match.get('locations', []) or []

            # æ”¶é›†æ‰€æœ‰å¯èƒ½çš„ goXRefs æ¥æºï¼ˆåˆ—è¡¨ï¼‰
            candidate_lists = []
            if isinstance(entry.get('goXRefs'), list):
                candidate_lists.append(entry.get('goXRefs'))
            if isinstance(signature.get('goXRefs'), list):
                candidate_lists.append(signature.get('goXRefs'))
            if isinstance(match.get('goXRefs'), list):
                candidate_lists.append(match.get('goXRefs'))

            # å°†æ‰€æœ‰ candidate åˆå¹¶ä¸ºç»Ÿä¸€çš„ go_terms listï¼ˆå»é‡ï¼‰
            go_terms: List[Dict[str, Any]] = []
            seen_go_ids = set()
            for gl in candidate_lists:
                for g in gl:
                    if not isinstance(g, dict):
                        continue
                    # å…¸å‹å­—æ®µ
                    gid = g.get('id') or g.get('GO') or g.get('goId')
                    gname = g.get('name') or g.get('term') or g.get('label')
                    gcat = g.get('category') or g.get('namespace') or g.get('type')

                    # å¦‚æœ id éæ ‡å‡†ï¼Œå°è¯•åœ¨å­—å…¸å€¼ä¸­æ­£åˆ™æå– GO:ddddddd
                    if not (isinstance(gid, str) and gid.startswith('GO:')):
                        for v in g.values():
                            if isinstance(v, str):
                                found = re.findall(r'GO:\d{7}', v)
                                if found:
                                    gid = found[0]
                                    break

                    if isinstance(gid, str) and gid.startswith('GO:'):
                        if gid not in seen_go_ids:
                            seen_go_ids.add(gid)
                            go_terms.append({
                                'id': gid,
                                'name': gname,
                                'category': gcat
                            })

            # å¦‚æœæ²¡æœ‰åœ¨ candidate_lists æ‰¾åˆ° goXRefsï¼Œä½† entry æˆ– signature é‡Œå¯èƒ½åŒ…å« GO å­—ç¬¦ä¸²ï¼ˆå¤‡ç”¨æŸ¥æ‰¾ï¼‰
            if not go_terms:
                # åœ¨ entry çš„ä»»æ„å­—ç¬¦ä¸²å­—æ®µä¸­æ‰¾ GO:xxxxxx
                for container in (entry, signature, match):
                    for v in (container or {}).values():
                        if isinstance(v, str) and 'GO:' in v:
                            founds = re.findall(r'GO:\d{7}', v)
                            for f in founds:
                                if f not in seen_go_ids:
                                    seen_go_ids.add(f)
                                    go_terms.append({'id': f, 'name': None, 'category': None})
                # ä»ä¸ºç©ºåˆ™ä¿ç•™ç©ºåˆ—è¡¨

            # å¯¹æ¯ä¸ª representative location ç”Ÿæˆä¸€æ¡è®°å½•
            for loc in locations:
                if not isinstance(loc, dict):
                    continue
                if not loc.get('representative', False):
                    continue

                record = {
                    'accession': signature.get('accession'),
                    'name': signature.get('name'),
                    'entry_accession': entry.get('accession'),
                    'entry_description': entry.get('description'),
                    'go_terms': go_terms.copy(),   # æ¯æ¡è®°å½•ç‹¬ç«‹æ‹·è´
                    'start': loc.get('start'),
                    'end': loc.get('end'),
                    'score': loc.get('score'),
                }
                out.append(record)

    return out

# =====================================================
# å‡½æ•°4ï¸âƒ£ï¼šå¯Œé›†åˆ†æ
# =====================================================
def go_analysis(records: List[Dict[str, Any]], obo_file: str = "go-basic.obo"):
    """
    ç»¼åˆ GO åˆ†æï¼š
    - å•è›‹ç™½/å°‘é‡ GO æ—¶ï¼šç»Ÿè®¡å¹¶æ‰“å° GO Term åˆ†å¸ƒ
    - å¤šè›‹ç™½/è¶³å¤Ÿ GO æ—¶ï¼šåšå¯Œé›†åˆ†æå¹¶æ‰“å°æ˜¾è‘— GO Term

    å‚æ•°:
        records (List[Dict]): extract_main_data è¾“å‡ºçš„è®°å½•åˆ—è¡¨
        obo_file (str): GO DAG æ–‡ä»¶è·¯å¾„
    """
    # æ”¶é›† GO æ³¨é‡Š
    protein_to_go = {}  # protein_index -> list of GO IDs
    for idx, rec in enumerate(records):
        go_ids = [go['id'] for go in rec.get('go_terms', []) if 'id' in go]
        if go_ids:
            protein_to_go[f"protein_{idx + 1}"] = go_ids

    all_go_ids = [go for gos in protein_to_go.values() for go in gos]
    if not all_go_ids:
        print("[âš ï¸] æ²¡æœ‰æ‰¾åˆ° GO æ³¨é‡Š")
        return

    # åŠ è½½ GO DAG
    godag = GODag(obo_file)

    # åˆ¤æ–­æ˜¯å¦åšå¯Œé›†åˆ†æ
    if len(protein_to_go) < 2 or len(all_go_ids) < 5:
        # å°‘é‡è›‹ç™½æˆ– GOï¼Œç›´æ¥ç»Ÿè®¡è¾“å‡º
        go_counter = Counter(all_go_ids)
        print(f"[ğŸ§¬] GO Term åˆ†å¸ƒç»Ÿè®¡ (å°‘é‡è›‹ç™½/GOï¼Œä¸åšå¯Œé›†åˆ†æ)ï¼šå…± {len(go_counter)} ä¸ª GO Term")
        for go_id, count in go_counter.most_common():
            term = godag.get(go_id)
            name = term.name if term else "Unknown"
            namespace = term.namespace if term else "Unknown"
            print(f"{go_id} | {name} | namespace: {namespace} | count: {count}")
        return

    # å¤šè›‹ç™½/GOï¼Œåšå¯Œé›†åˆ†æ
    # æ„å»ºèƒŒæ™¯é›†ï¼šæ‰€æœ‰è›‹ç™½çš„ GO
    population = set(all_go_ids)
    assoc = {p: gos for p, gos in protein_to_go.items()}
    study = list(population)  # ç®€åŒ–å¤„ç†ï¼Œç”¨æ‰€æœ‰ GO åšç ”ç©¶é›†

    # åˆå§‹åŒ–å¯Œé›†åˆ†æ
    goeaobj = GOEnrichmentStudyNS(
        list(population),
        assoc,
        godag,
        propagate_counts=True,
        alpha=0.05,
        methods=["fdr_bh"]
    )

    # æ‰§è¡Œåˆ†æ
    goea_results_all = goeaobj.run_study(study)

    # æ˜¾è‘— GO Term
    sig_results = [r for r in goea_results_all if r.p_fdr_bh < 0.05]

    if not sig_results:
        print("[â„¹ï¸] æ²¡æœ‰æ˜¾è‘—å¯Œé›† GO Term")
        return

    # è¾“å‡ºç»“æœ
    print(f"[ğŸ§ª] æ˜¾è‘—å¯Œé›† GO Term (FDR < 0.05)ï¼šå…± {len(sig_results)} ä¸ª")
    for r in sig_results:
        print(f"{r.GO} | {r.name} | namespace: {r.NS} | p_fdr_bh: {r.p_fdr_bh:.4g} | study_count: {r.study_count}")


# =====================================================
# ç¤ºä¾‹ç”¨æ³•
# =====================================================
if __name__ == "__main__":
    pdb_path = "3cdd1.pdb"  # ä½ çš„PDBæ–‡ä»¶è·¯å¾„
    # ä»PDBä¸­æå–åºåˆ—
    seq = extract_sequence_from_pdb(pdb_path)
    print(f"[ğŸ§¬] æå–åˆ°çš„åºåˆ—é•¿åº¦: {len(seq)}")
    # ä½¿ç”¨InterProé¢„æµ‹åŠŸèƒ½
    result = interpro_predict(seq, email="2805238699@qq.com")
    # æ‰“å°ç»“æœæ‘˜è¦
    print(extract_main_data(result))
    # è¿›è¡Œå¯Œé›†åˆ†æ
    go_analysis(extract_main_data(result))